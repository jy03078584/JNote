#并发/同步
[TOC]


##CAS(Compare And Swap)
> cas：本质是利用CPU对内存中的数据操作的特殊指令，该指令会对内存中的数据做原子操作。CAS可简单理解为有3个操作数(内存值V，预期值A，被修改后的值B)
步骤：
  1.CPU对当前内存值V与预期值A做比较。
  2.若V与A相等，则执行修改操作，将V替换成B
  3.若V与A不相等，则不做修改，返回原来的内存值V
CAS是乐观锁的一种思想，而Synchronized是悲观锁。
<br>
CAS缺点和不足：CAS虽然高效的解决了原子操作问题，但仍然有不足之处：
  1.ABA问题：CAS只判断当前内存值和预期内存值是否相等，想当然的认为中途没有其他操作修改过内存值，若出现内存被改动后又改回初始值，A——>B——>A。则不能保证没有发生变化。解决思路：给变量加上版本标识号，1A-2B-3A
  2.循环时间过长，开销较大。
  3.CAS只能保证一个变量的原子操作，对于多个变量时无法保证。解决思路：①使用锁synchorized；②将多个变量封装在一个变量


##AQS(AbstractQueuedSynchronizer)
> AQS是JDK1.5提供的一个基于FIFO等待队列实现的一个用于实现同步器的基础框架，JCU包里面几乎所有的有关锁、多线程并发以及线程同步器等重要组件的实现都是基于AQS这个框架。AQS的核心思想是基于volatile int state这样的一个属性同时配合Unsafe工具对其原子性的操作来实现对当前锁的状态进行修改。当state的值为0的时候，标识该Lock不被任何线程所占有。



##Synchronized/Lock

###synchorized
> 由于多线程比单线程更加不确定性，在处理共享变量时需要同步处理

- 同步原理：每个java对象中都持有Monitor锁对象，JVM使用monitorenter和monitorexit来实现同步处理。Java中使用Synchronized关键字标记方法/代码块需要同步。线程获取锁时对象的monitorenter+1，线程释放锁时monitorexit-1.
- Java中每个对象都能作为锁

> 同步方法，锁是当前实例对象

- 会互斥其他线程对该对象的synchonized方法访问
- 不会互斥其他线程对其他非synchonized方法
- 不会互斥其他线程对另一个对象的synchonized方法

> 同步静态方法，锁是当前对象的Class对象<br>
  
  - 锁对象是Class
  - 不会互斥其他线程对该类的非static synchonized的访问
  
> 同步方法块，锁是Synchonized括号里配置的对象<br>
  
  - 锁对象即是synchonized(object)中的对象 
  - 同步代码块能更小粒度的控制同步范围，提升性能


> Synchronized的缺陷
  **1.影响效率**：释放synchronized修饰的代码块的锁只有2种情况：①执行完代码块②代码发生异常，这就导致不可控性，若代码中需要执行较长时间操作(IO阻塞..)会导致其他线程长时间等待
  **2.读写全锁**：对于有些操作，只需要对写操作加锁，采用synchorized则会将读读操作也加锁。


***
###Lock
> 为减少获得和释放锁带来的消耗，JDK6引入偏向锁,轻量锁。因此JDK6后用有4种锁状态：无锁状态，偏向锁状态，轻量锁状态，重量锁状态。随着应用竞争的升级，锁状态也会依次升级(不可逆)。<br>
  **1.偏向锁**：在JDK6,7是默认开启的。线程获得偏向锁后，JVM会将线程ID存入锁对象的对象头里，下次该线程进入和退出同步块时则不需要在CAS去操作加锁解锁直接查看锁对象的对象头里存放的线程ID是否匹配即可；偏向锁只有在出现竞争的情况才会释放锁<br>
  **2.轻量锁**：轻量级锁并不是用来代替重量级锁的，它的本意是在没有多线程竞争的前提下，减少传统的重量级锁使用产生的性能消耗。轻量级锁所适应的场景是线程交替执行同步块的情况，如果存在同一时间访问同一锁的情况，就会导致轻量级锁膨胀为重量级锁。<br>
  **相对Synchronized来说：Lock需要手动去释放锁**

  * 可重入锁：线程已获取某个对象的锁后访问同步/锁代码块时无需再次申请锁，Synchronized和ReentLock都是可重入锁
  * 可中断锁：线程在等待释放锁的过程中是否可以中断等待,Synchronized是不可中断,Lokc则可中断
  * 公平锁：  根据等待锁的时间来确定锁的获得者,Synchronized是非公平锁，ReentrantLock和ReentrantReadWriteLock默认也是非公平锁，但可在构造函数中设置为公平锁
  * 读写锁：  将锁分离成读锁和写锁

- **Lock接口**
```java
  
public interface Lock {

  void lock();
  void lockInterruptibly() throws InterruptedException;
  boolean tryLock();
  boolean tryLock(long time, TimeUnit unit) throws InterruptedException;
  void unlock();
  Condition newCondition();

}
```


<font color=red face="黑体">由于单独调用Thread中interrupt方法不能中断运行中的线程，只能中断阻塞中的线程。因此等待synchonized修饰的锁的线程是不能被中断的从而一直等待下去，而Lock的lockInterruptibly能让等待线程响应interrupt()</font>


- **ReentrantLock**
  + ReentrantLock(可重入锁)，是唯一实现了Lock接口的类。
  + Synchronized也是可重入锁，可重入锁简单理解：一个已经获取该对象的锁的线程在访问另一个加锁方法时不再需要重新申请锁
  ```java
  public synchronized void method1(){method2()}//访问method2时不需要再申请锁，否则永远等待
  public synchronized void method2(){...}
  ```
  + 原理
  ReentrantLock主要通过一个Sync(继承AbstractQueuedSynchronizer)的内部抽象类，以及它的2个实现类NoFairSync，FairSync。分别用于实现公平锁和非公平锁。

  **ReentrantLock的核心是AQS实现**
  - 主要提供exclusiveOwnerThread属性用于关联当前持有该锁的线程。
  - 等待队列：对于等待获取锁的线程，AQS采用一个双向链表的队列存储。当多线程竞争锁时，采用CAS改变state的值，更改成功则成功获取锁。竞争失败的线程再次尝试获取锁仍然失败则进入等待队列。
  - AQS的等待队列中尝试获取锁的机制很巧妙，因为是FIFO因此只需要NO1线程尝试获取锁，若失败则设置waitStatus为SIGNAL(-1)，当下次再发起尝试操作仍然失败后发现watiStatus已经为SINGAL则挂起线程。而队列后面的线程本身无需去尝试获取锁，只需要判断前面的线程waitStauts状态即可，若Prev线程为SINGAL则自己挂起。
  - 释放锁/唤醒等待队列：当锁被释放后state重置为0,exclusiveOwnerThread=null。同时唤醒队列中首个被挂起的线程准备获取锁。

- **ReadWriteLock读写锁(非LOCK子接口)**
  + ReentrantReadWriteLock实现了ReadWriteLock，读写锁将锁分离提高并发效率
  + 如果有一个线程已经占用了**读锁**，则此时其他线程**申请写锁**的线程会一直等待释放读锁。
  + 如果有一个线程已经占用了**写锁**，则此时其他线程**申请读写锁**会一直等待释放写锁



***
- **Lock与Synchronized比较**
+ Lock是接口(内部由CAS实现),而synchronized是Java中的关键字,synchronized是内置的系统语言实现,JVM对Synchronized有优化；
+ synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁；
+ Lock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断；
+ 通过Lock可以知道有没有成功获取锁，而synchronized却无法办到。
+ Lock可以提高多个线程进行读操作的效率。在性能上来说，如果竞争资源不激烈,Synchronized性能更好,而当竞争资源非常激烈时（即有大量线程同时竞争），此时Lock的性能要远远优于synchronized。
+ ReentrantLock可以多次调用newCondition()来同时绑定多个Condition对象
+ JDK1.6之前ReentrantLock的效率要好于Synchronized,1.6之后JVM对原生的Synchronized加入了多项优化使得Synchronized与Lock的性能几乎持平,而且优化会持续进行。因此性能因素不应该是代码中选择ReentLock的理由



***
###wait(),notify(),notifyAll(),Condition
- wait(),notify(),notifyAll()
1. wait(),notify(),notifyAll()都是Object下的native final方法
2. 声明在Object而不是Thread是因为每个对象都拥有各自的Monitor(锁)。
3. 调用wait(),notify(),notifyAll()必须在同步代码块中调用，因为调用者必须持有锁对象
4. wait()一般也都是在循环块中调用的，因为有时会出线伪唤醒的情况(一个wait线程被notify后还需要检查是否符合执行条件，不符合则需要再次被wait)

**调用对象的notify()后会唤醒等待线程，但仅仅是唤醒线程，并没有获得对象锁**
<br>**wait()会放弃对象锁；而Thread.sleep()只是暂停当前线程，让出CPU并不释放锁。**
<hr>
- Condition
Condition是JDK5后JCU包下提供用来替代wait()，在并发上更高效便捷。
Conditon.await()====>Object.wait()
Conditon.signal()===>Object.notify()
Condition.singalAll()===>Object.notifyAll()

**Condition依赖Lock 需要在lock()和unlock()代码范围中执行**



***
##线程
### Java线程基础
  * 创建线程的方式 继承Thread，实现Runnable接口。相比继承Thread的方式，Runnable有特点:
    1)接口替代继承，避免java不能多继承的问题
  
  * run(),start()；只有执行了start()线程才会真正创建，否则直接调用run()是在当前线程执行。一个线程只能启动一次(start)，启动多次会抛出异常。
  * 线程5种状态：
    **1)NEW新建**:通常指new Thtread()<br>
    **2)RUNNABLE可运行**：
      1.调用了Thread.start()进入等待就绪状态，等待获取CPU使用权
      2.从BLOCKED状态结束后重新RUNNABLE<br>
    **3)RUNNING运行中**：获得CPU使用权，执行Thread中的方法<br>
    **4)BLOCKED阻塞**:因某种原因失去了CPU使用权。等待回到RUNNABLE状态从而重新RUNNING
      1.等待阻塞：执行了wait()，JVM将线程挂起
      2.同步阻塞：等待获取对象锁而被阻塞
      3.其他阻塞：线程执行了sleep(),join()或者发起IO操作而被阻塞<br>
    **5)DEAD死亡**：线程执行完毕或者执行抛出异常
    <br>

### Java线程池
- 实际中并发量较大，需要大量线程的情况下，直接new的方式会频繁的创建销毁线程，大大降低系统效率，可以考虑使用线程池的方式替代。

- **Java线程池ThreadPoolExecutor中4种状态：**
  1.Running：线程池创建后Running状态
  2.Shutdown：调用了shutdown()后的状态，此状态不可接受新的任务，并等待已接受任务执行完
  3.Stop：调用了shutdownNow()后的状态，此状态不可接受新的任务，并尝试终止正在执行的任务
  4.TERMINATED：线程被置于Shutdown/stop后并且所有线程已销毁、任务队列已清空、任务执行完后的状态
  <br>
- **ThreadPoolExecutor处理策略：**
  1.如果当前线程池中的线程数目小于corePoolSize，每来一个任务，会创建一个线程去执行这个任务；
  2.如果当前线程池中的线程数目>=corePoolSize，则每来一个任务，会尝试将其添加到任务缓存队列当中，若添加成功，则该任务会等待空闲线程将其取出去执行；若添加失败（一般来说是任务缓存队列已满），则会尝试创建新的线程去执行这个任务；
  3.如果当前线程池中的线程数目达到maximumPoolSize，则会采取任务拒绝策略进行处理；
  4.如果线程池中的线程数量大于 corePoolSize时，如果某线程空闲时间超过keepAliveTime，线程将被终止，直至线程池中的线程数目不大于corePoolSize；如果允许为核心池中的线程设置存活时间，那么核心池中的线程空闲时间超过keepAliveTime，线程也会被终止。
  <br>
- **WorkQueue中的排队策略：**
  1.ArrayBlockingQueue：基于数组的先进先出队列，此队列创建时必须指定大小(使用较少)；
  2.LinkedBlockingQueue：基于链表的先进先出队列，如果创建时没有指定此队列大小，则默认为Integer.MAX_VALUE；
  3.synchronousQueue：这个队列比较特殊，它不会保存提交的任务，而是将直接新建一个线程来执行新来的任务
  <br>
- **当线程池中线程达到maximumPoolsize,继续有任务加入时会采取决绝策略：**
  1.ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。 
  2.ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。 
  3.ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）
  4.ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 
  <br>
- **Java提供的3个默认线程池 不建议自己继承ThreadPoolExecutor**
  1.newFixedThreadPool创建数量固定的线程池。corePoolSize和maximumPoolSize值是相等的，使用LinkedBlockingQueue；
  2.newSingleThreadExecutor创建单一线程的线程池。corePoolSize和maximumPoolSize都设置为1,使用LinkedBlockingQueue；
  3.newCachedThreadPool将corePoolSize设置为0，将maximumPoolSize设置为Integer.MAX_VALUE，使用SynchronousQueue，任务到来后直接创建线程运行，当线程空闲超过60秒销毁线程
  <br>
- **合理配置线程池大小**
  需要根据实际情况具体分析，可从业务类型方面考虑
  CPU密集型：应尽量压榨CPU,避免过多的上下文切换 参考 ：CPU内核数+1
  IO密集型：可适当加大线程数,以便在等待IO时能处理其他业务.CPU内核数/(1-阻塞系统)  阻塞系数一般0.8——0.9


##并发

###死锁
- 死锁原理：一组进程中的各个进程均占有不会释放的资源，但因互相申请被其他进程所站用不会释放的资源而处于的一种永久等待状态。
- 死锁条件
  1. 互斥条件：一个资源被一个进程获取后,不可被其他进程获取。
  2. 请求保持条件：一个进程因请求资源导致被阻塞时,不会释放已获得的资源。
  3. 不可剥夺条件：进程已获得的资源，在进程未使用完之前不可被其他进程强行剥夺。
  4. 循环等待条件：若干进程因相互等待资源形成循环等待的关系
- 实现一个死锁
```java
class TestDeadLock implements Runnable {
  int a,b;
  TestDeadLock(int a,int b){
    this.a = a;
    this.b = b;
  }

  
  //jvm对Integer对象在[-127,128]间作了缓存处理
  public void run(){
    synchronized(Integer.valueOf(a)){
      synchronized(Integer.valueOf(b)){
        System.out.println(a + b);
      } 
    } 
  }

  public static void main(String[] args) {
    for (int i = 0;i < 100 ;i++ ) {
      new Thread(new TestDeadLock(1,2)).start();
      new Thread(new TestDeadLock(2,1)).start();
    }
  }
}
```

***
###CopyOnWrite容器
- **CopyOnWirte容器**：JDK1.5后新增的并发容器。在对容器进行写操作时，并没有直接往容器添加内容，而是先对容器进行Copy出一个新的容器，然后对新的容器进行写操作，最后将原容器的引用指向新Copy的容器。CopyOnWrite的好处：避免多线程操作时写操作需要加锁的问题，提供一种读写分离的机制。

- CopyOnWrite容器在写时会加锁(防止出现多个拷贝)
	CopyOnWriteArrayList中add源代码：
```java
    public boolean add(T e){
    	final ReentrantLock lock = this.lock;
    	lock.lock
    	try{
    		//copy集合
   		//原数组引用指向新数组
    	}finally{
    		lock.unlock();
    	}
    }
```
- **CopyOnWrite缺点**
因为需要Copy原集合，造成内存中有多份对象，当集合较大时容易造成频繁的Yong代GC甚至Full GC。CopyOnWirte可用ConcurrenctHashMap替换
- CopyOnWrite集合适合读多写少的场景


***
###ConcurrenctHashMap
- **ConcurrenctHashMap内部结构**：Segment数组+HashEntry链表数组
  Segment是ReentrantLock数组，在ConcurrenctHashMap中扮演锁的角色。1个Segment内部又类似HashMap，一个Segment维护一个HashEntry数组，每个HashEntry则是一个链表结构。

- **ConcurrenctHashMap的分段锁机制**：不同于HashTable所有线程竞争同一锁，ConcurrenctHashMap给每一个Segment分配一把锁，当多线程访问不同段数据时只会争夺各自段的segment。极大提高并发性能
- **ConcurrenctHashMap初始化**
  **1.**通过concurrentLevel计算出segment数组的大小(不小于level的2的指数，以便加快hash计算)
  **2.**根据intialCapacity计算每个segment容量大小(与hashMap一样 默认大小16，负载因子0.75)<br>
- **定位Segment**：ConcurcentHashMap对hashcode进行再hash计算(降低hash冲突)定位segment
- **ConcurcentHashMap.get方法**:
ConcurcentHashMap在get读取数据时没有加锁操作，因此效率较高：因为get操作中需要共享的变量都定义为volatile,volatile的happen-before机制保证write操作优先read操作
  **1.**定位segment位置
  **2.**在特地给的segment==>根据hash获取特定链表的头===>根据key在特定链表上遍历获取value;(若为null则加锁等待put操作后再get)<br>
- **ConcurcentHashMap.put方法**：写操作需要加锁(只写对所在segment加锁)
  **1.**判断是否需要扩容(相比HashMap的插入后判断扩容,ConcurcentHashMap插入前判断更加恰当，能避免无意义的扩容)。ConcurcentHashMap的扩容只针对Segment不会对整个ConcurcentHashMap扩容。
  **2.**根据getFirst(int hash)获取链表头===>遍历链表找到key这更新value否则新增到头部<br>
- **ConcurcentHashMap的size方法**：
计算ConcurcentHashMap的元素数量，每个Segment中维护了一个volatile的count记录元素，但ConcurcentHashMap并不是简单求和count。而是先通过2次不加锁求和count比较，2次不同则进行一次加锁求和。
- **ConcurcentHashMap的remove方法**：
为了防止破坏链表结构HashEntry中的next是final修饰的，导致在删除不能直接修改链表的next。而是在复制待删除元素前面的元素然后新加入到链表中。

***
###Time/TimeTask
Time：时间调度器。TimeTask：具体要调度的任务。

```java
//经过delay(ms)后开始进行调度，仅仅调度一次
public void schedule(TimerTask task, long delay) 
//在指定的Date上调度一次。
public void schedule(TimerTask task, Date time) 
//在deplay后开始调度，每次调度完后，最少等待period后开启下一次调度
public void schedule(TimerTask task, long delay, long period) 
public void schedule(TimerTask task, Date firstTime, long period)
/*
**相对shedule来说,如果因CPU调度原因导致某一次调度延迟了2S,则后续调度均会延迟2S而会引起少调度的问题。
*scheduleAtFixedRate则会计算出距离正确下次调度需要等待的时间 重新加入等待队列 等待调度
*/  　　
public void scheduleAtFixedRate(TimerTask task, long delay, long period)
//多线程中则使用Executors构建调度池
Executors.newScheduledThreadPool();
```

1. 一个Timer内部包装了“一个Thread”和“一个Task”队列。这个队列按照最小堆的方式对任务进行排列；而包含的线程在Timer的构造方法调用时被启动，这个Thread的run方法无限循环这个Task队列。若队列为空且没有调用Timer的cancel方法，此时会一直等待，也就是死循环；如果等待完成后，队列为空，则认为发生了cancel从而跳出死循环，结束任务；循环中如果发现任务需要执行的时间小于系统时间，则需要执行，那么根据任务的时间片从新计算下次执行时间，若时间片为0代表只执行一次，则直接移除队列即可。
2. TimerTask的cancel方法是取消单个任务的执行，即将其状态置为CANCELLED，这样在调用Timer的purge方法时，会将任务队列中状态为CANCELLED的任务清除，并对最小堆进行重排序。
3. 任务队列是用最小堆实现的。

***
###ThreadLocal
ThreadLocal使得每个线程能独立的处理某些对象。但ThreadLocal本质不是用来处理线程共享问题的，因为其他线程根本无法访问到ThreadLocal的对象。
  1. Thread类中维护着一个ThreadLocalMap变量,ThreadLocalMap本质是一个Map,其中key是ThreadLocal对象(不是Thread),value是要线程独立操作的对象
  2. ThreadLocalMap是定义在ThreadLocal里的内部类，但却是在Thread中维护使用的。
  3. ThreadLocal决定了每个线程独自拥有变量，而非拷贝和共享

ThreadLocal常用场景：Session和数据库连接上。
Spring系列、Struts2、Hibernate在多线程上都大量使用了ThreadLocal。

***
###CountDownLatch、CyclicBarrier、Semaphore
####CountDownLatch
  ConntDownLatch位于JCU包下,利用计数的功能,实现一个线程等待其他线程完成操作后再执行的功能,不可重复使用
  
  ```java
  public CountDownLatch(int count) { };  //count为计数值
  public void await() throws InterruptedException { };//线程挂起,直到count减为0
  public boolean await(long timeout, TimeUnit unit) throws InterruptedException { };//最大等待时间
  public void countDown() { };  //count值减1
  ```

####CyclicBarrier
  CyclicBarrier位于JCU包下,实现一组线程相互等待至某一状态后再统一放行。CyclicBarrier可以重复使用
  
  ```java
  //parties:需要等待的线程数,action:线程恢复后需要其中一个线程执行的任务
  public CyclicBarrier(int parties, Runnable barrierAction){}
  public CyclicBarrier(int parties){}
  //挂起线程 等待其他线程
  public int await() throws InterruptedException, BrokenBarrierException{};
  ```

####Semaphore
  Semaphore位于JCU包下,能控制同一时刻并发的线程数。获取许可acquire后方能执行。
  
```java
  public Semaphore(int permits){}//同时能并发执行的线程数为permits 默认不公平
  public Semaphore(int permits, boolean fair){}//累死ReentLock 构造器能指定等待线程是否公平
  
  public void acquire() throws InterruptedException {}//获取一个许可（阻塞）
  public void acquire(int permits) throws InterruptedException { } //获取permits个许可（阻塞）
  public void release() { } //释放一个许可（阻塞）
  public void release(int permits) { } //释放permits个许可（阻塞）
  //例：虽然线程池中有30条线程 但Semphore限制同一时刻只能允许10个线程并发访问DB
  private static Semaphore sp = new Semphore(20);
for(int i=0;i<=30;i++){
  threadPool.execute(new Runnable(){
        public void run(){
          try{
              sp.acquire();//获得许可
             //insert update DB操作
              sp.release();//释放许可
            }catch(Exception e){
             ///
            }
        }
      });
  }
  
```
